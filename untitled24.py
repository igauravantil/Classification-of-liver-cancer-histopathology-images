# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/127JHUpPGOmzsrYLM6TiDjtVEExRhXkbN
"""

import cv2
import matplotlib.pyplot as plt
from sklearn.feature_extraction import image
import numpy as np
import glob
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.preprocessing import image as ig
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img
from keras.models import Sequential
from keras.layers import Dense, ReLU, LeakyReLU, PReLU, ELU, Dropout, InputLayer, Softmax
from sklearn.model_selection import train_test_split
import keras
from sklearn.metrics import accuracy_score
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense
from keras.losses import Loss
from matplotlib import pyplot
from numpy import mean
from numpy import std
from numpy import array
from numpy import argmax
from numpy import tensordot
from numpy.linalg import norm
from scipy.optimize import differential_evolution
import random
from sklearn.metrics import confusion_matrix,f1_score
from sklearn.metrics import precision_recall_fscore_support
from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img

a1 = glob.glob('/content/drive/My Drive/normal/*')
a2 = glob.glob('/content/drive/My Drive/cancer/*')

datagen=ImageDataGenerator(
    rotation_range=50,
    width_shift_range=0.4,
    height_shift_range=0.4,
    fill_mode="wrap",
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2
)

"""**Normal Data Augumentation**"""

for j in len(normal):
  img=cv2.imread(normal[i])
  img=img.reshape((1,)+img.shape)
  i=0
  for batch in datagen.flow(img1,batch_size=1,save_to_dir='/content/drive/My Drive/Normal_augument/',save_prefix='Normal_vector',save_format='png'):
    i=i+1
    if i>40:
      break

"""**Abnormal Data Augumentation**"""

for j in len(abnormal):
  img=cv2.imread(abnormal[i])
  img=img.reshape((1,)+img.shape)
  i=0
  for batch in datagen.flow(img,batch_size=1,save_to_dir='/content/drive/My Drive/Abnormal_augument/',save_prefix='Abnormal_vector',save_format='png'):
    i=i+1
    if i>20:
      break

a1 = glob.glob('/content/drive/My Drive/normal/*')
b1 = glob.glob('/content/drive/My Drive/Normal_augument/*')
a2 = glob.glob('/content/drive/My Drive/cancer/*')
b2 = glob.glob('/content/drive/My Drive/Abnormal_augument/*')

a1.extend(b1)
normal=a1
a2.extend(b2)
abnormal=a2

"""**ResNet50**"""

resnet=ResNet50(include_top=False,weights='imagenet',pooling="avg")
for layers in resnet.layers:
  layers.trainable=False

"""**Abnormal Image Preprocessing**"""

for z in range(len(abnormal)):
    img = cv2.imread(abnormal[z])
    cv2.imwrite("Original.png",img)
    hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
    cv2.imwrite("HSV_Image.png",hsv_img)
    h=hsv_img[:,:,0]
    s=hsv_img[:,:,1]
    v=hsv_img[:,:,2]
    ret1,h1 = cv2.threshold(h,0,179,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)
    ret2,s1 = cv2.threshold(s,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)
    otsu_img = cv2.merge([h1,s1,v])
    cv2.imwrite("Otsu's.png",otsu_img)
    rgb_img = cv2.cvtColor(otsu_img,cv2.COLOR_HSV2RGB)
    lab_img=cv2.cvtColor(rgb_img,cv2.COLOR_RGB2LAB)
    cv2.imwrite("Lab Image.png",lab_img)
    l=lab_img[:,:,0]
    a=lab_img[:,:,1]
    b=lab_img[:,:,2]
    cla=cv2.createCLAHE(clipLimit=3.0,tileGridSize=(8,8))
    cla_img=cla.apply(l)
    final_img = cv2.merge((cla_img,a,b))
    cv2.imwrite("FInal RGB.png",final_img)
    final_img=cv2.cvtColor(final_lab_img,cv2.COLOR_LAB2RGB)
    l,b,h = final_img.shape
    pat = int((l*b)/(224*224))*3
    patches = image.extract_patches_2d(final_img,(224,224),pat)
    temp=0
    preds_lists=[]
    print(len(patches))
    for i in range(len(patches)):
        a = patches[i][:,:,1]
        hist = cv2.calcHist([a],[0],None,[256],[0,256])
        temp = ((hist[127]+hist[128]+hist[129])/(224*224))*100
        if(temp<50):
            flag = cv2.cvtColor(patches[i],cv2.COLOR_LAB2RGB)
            x=np.expand_dims(flag,axis=0)
            x=preprocess_input(x)
            preds=resnet.predict(x)
            preds_lists.append(preds)
    d=[]
    for j in range(2048):
      pnorm = 0
      p = 3
      for g in range(len(preds_lists)):
        r=preds_lists[g]
        pnorm += np.abs(r[0][j]) ** p
      if len(preds_lists)>0:
        pnorm=pnorm/len(preds_lists)
      else:
        continue
      h=pnorm ** (1. / p)
      d.append(h)
    t=np.array(d)
    print(t.shape)
    np.save("/content/drive/My Drive/Abnormal_Image_Vectors/cancer"+str(z)+".npy",t,allow_pickle=True)

"""**Normal Image Preprocessing**"""

for z in range(len(normal)):
    img = cv2.imread(normal[z])
    cv2.imwrite("Original.png",img)
    hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
    cv2.imwrite("HSV_Image.png",hsv_img)
    h=hsv_img[:,:,0]
    s=hsv_img[:,:,1]
    v=hsv_img[:,:,2]
    ret1,h1 = cv2.threshold(h,0,179,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)  
    ret2,s1 = cv2.threshold(s,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)  
    otsu_img = cv2.merge([h1,s1,v])
    cv2.imwrite("Otsu's.png",otsu_img)
    rgb_img = cv2.cvtColor(otsu_img,cv2.COLOR_HSV2RGB)
    lab_img=cv2.cvtColor(rgb_img,cv2.COLOR_RGB2LAB)  
    cv2.imwrite("Lab Image.png",lab_img)
    l=lab_img[:,:,0]
    a=lab_img[:,:,1]
    b=lab_img[:,:,2]
    cla=cv2.createCLAHE(clipLimit=3.0,tileGridSize=(8,8))
    cla_img=cla.apply(l)
    final_img = cv2.merge((cla_img,a,b))
    cv2.imwrite("FInal RGB.png",final_img)
    final_img=cv2.cvtColor(final_lab_img,cv2.COLOR_LAB2RGB)
    l,b,h = final_img.shape
    pat = int((l*b)/(224*224))*3
    patches = image.extract_patches_2d(final_img,(224,224),pat)
    temp=0
    preds_lists=[]
    print(len(patches))
    for i in range(len(patches)):
        a = patches[i][:,:,1]
        hist = cv2.calcHist([a],[0],None,[256],[0,256])
        temp = ((hist[127]+hist[128]+hist[129])/(224*224))*100
        if(temp<50):
            flag = cv2.cvtColor(patches[i],cv2.COLOR_LAB2RGB)
            x=np.expand_dims(flag,axis=0)
            x=preprocess_input(x)
            preds=resnet.predict(x)
            preds_lists.append(preds)
    d=[]
    for j in range(2048):
      pnorm = 0
      p = 3
      for g in range(len(preds_lists)):
        r=preds_lists[g]
        pnorm += np.abs(r[0][j]) ** p
      if len(preds_lists)>0:
        pnorm=pnorm/len(preds_lists)
      else:
        continue
      h=pnorm ** (1. / p)
      d.append(h)
    t=np.array(d)
    print(t.shape)
    np.save("/content/drive/My Drive/Normal_Image_Vectors/cancer"+str(z)+".npy",t,allow_pickle=True)

"""**Feature Selection**"""

a_vectors=glob.glob('/content/drive/My Drive/Abnormal_Image_Vectors/*')
n_vectors=glob.glob('/content/drive/My Drive/Normal_Image_Vectors/*')
print(len(a_vectors))
print(len(n_vectors))

d1=[1.0]
v1=[]
for i in range(len(n_vectors)):
  v1.append(d1)
print(len(v1))
n_dic={}
n_dic= {n_vectors[i]:v1[i] for i in range(len(v1))}
d2=[0.0]
v2=[]
for i in range(len(a_vectors)):
  v2.append(d2)
print(len(v2))
a_dic={}
a_dic= {a_vectors[i]:v2[i] for i in range(len(v2))}

a_vectors.extend(n_vectors)
a_dic.update(n_dic)
random.shuffle(a_vectors)

x=[]
y=[]
for i in range(len(a_vectors)):
  a=np.load(a_vectors[i],allow_pickle=True)
  if(a.shape[0]>0):
    b=a[0:104]
    c=a[1944:2048]
    d=np.append(b,c)
    x.append(d)
    y.append(np.array(a_dic[a_vectors[i]]))

x_train=x[:3059]
x_test=x[3059:3715]
x_val=x[3715:4370]
y_train=y[:3059]
y_test=y[3059:3715]
y_val=y[3715:4370]
x_train=np.array(x_train)
x_test=np.array(x_test)
x_val=np.array(x_val)
y_train=np.array(y_train)
y_test=np.array(y_test)
y_val=np.array(y_val)

"""**Ensemble Model Designing**"""

def fit_model(trainX, trainy):
    trainy_enc = to_categorical(trainy)
    model=Sequential()
    model.add(InputLayer(input_shape=(200)))
    model.add(Dropout(0.4))
    model.add(Dense(units=200, activation='relu',kernel_initializer='he_uniform'))
    model.add(Dropout(0.4))
    model.add(Dense(units=100, activation='relu',kernel_initializer='he_uniform'))
    model.add(Dense(units=2, kernel_initializer='glorot_uniform',activation='softmax'))
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.binary_crossentropy,metrics=tf.keras.metrics.categorical_accuracy)
    model.fit(x_train,trainy_enc,epochs=10,batch_size=24)
    return model

"""**Model Training**"""

n_members = 10
members = [fit_model(x_train,y_train) for _ in range(n_members)]

"""**Prediction and calculating the means from all models**"""

y_test_preds = []
y_val_preds = []
for i in range(10):
  y_test_preds.append(members[i].predict(x_test))
  y_val_preds.append(members[i].predict(x_val))

y_test_preds_mean = []
y_val_preds_mean = []
for i in range(len(y_test_preds[0])):
  temp1 = 0
  for j in range(10):
    temp1 += y_test_preds[j][i]
  y_test_preds_mean.append(temp1/10)
for i in range(len(y_val_preds[0])):
  temp2 = 0
  for j in range(10):
    temp2 += y_val_preds[j][i]
  y_val_preds_mean.append(temp2/10)

y_test_final_pred = []
y_val_final_pred = []
for i in range(len(y_test_preds_mean)):
  if(y_test_preds_mean[i][0]>0.5):
    y_test_final_pred.append(0)
  else:
    y_test_final_pred.append(1)
for i in range(len(y_val_preds_mean)):
  if(y_val_preds_mean[i][0]>0.5):
    y_val_final_pred.append(0)
  else:
    y_val_final_pred.append(1)

"""**Accuracy Scores**"""

test_acc_score = accuracy_score(y_test,y_test_final_pred)
val_acc_score = accuracy_score(y_val,y_val_final_pred)
print(test_acc_score,val_acc_score)

"""**Confusion Matrices**"""

test_con_mat = confusion_matrix(y_test,y_test_final_pred)
val_con_mat = confusion_matrix(y_val,y_val_final_pred)

"""**Recall, Precisions, F1 Scores**"""

test_pr = precision_recall_fscore_support(y_test, y_test_final_pred, average='micro')
val_pr = precision_recall_fscore_support(y_val, y_val_final_pred, average='micro')

precision = [test_pr[0],val_pr[0]]
recall = [test_pr[1],val_pr[1]]
accuracy = [test_acc_score,val_acc_score]

test_data = np.array([test_pr[0],test_pr[1],test_acc_score])
val_data = np.array([val_pr[0],val_pr[1],val_acc_score])

test_data = np.array([test_pr[0],test_pr[1],test_acc_score])
val_data = np.array([val_pr[0],val_pr[1],val_acc_score])

"""**Data Visualization**"""

x = np.arange(len(test_data))

fig, ax = plt.subplots(figsize=(5,5))
index = np.arange(len(test_data))
testbar = ax.bar(index-(0.35/2),test_data,0.35,label='Test Data')
valbar = ax.bar(index+(0.35/2),val_data,0.35,label='Validation Data')

ax.set_xticks(index)
ax.set_xticklabels(['Precision',"Recall",'Score'])
ax.legend()
plt.savefig('multiple graph.png', dpi=300, bbox_inches='tight')
plt.show()

test_f1 = f1_score(y_test,y_test_final_pred)
val_f1 = f1_score(y_val,y_val_final_pred)

x = np.arange(len(test_data))
test_graph_data = np.array([test_pr[0],test_pr[1],test_acc_score,test_f1])
fig, ax = plt.subplots(figsize=(5,5))
index = np.arange(len(test_graph_data))
testbar = ax.bar(index,test_graph_data,0.35,label='Test Data')

ax.set_xticks(index)
ax.set_xticklabels(['Precision',"Recall",'Score','f1 score'])

plt.ylabel('Score')
ax.legend()

plt.savefig('test graph.png', dpi=300, bbox_inches='tight')

plt.show()

x = np.arange(len(test_data))
val_graph_data = np.array([val_pr[0],val_pr[1],val_acc_score,val_f1])
fig, ax = plt.subplots(figsize=(5,5))
index = np.arange(len(val_graph_data))
valbar = ax.bar(index,val_graph_data,0.35,label='Val Data')

ax.set_xticks(index)
ax.set_xticklabels(['Precision',"Recall",'Score','f1 score'])
ax.legend()

plt.show()
plt.savefig('plot.png', dpi=300, bbox_inches='tight')